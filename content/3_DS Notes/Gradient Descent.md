#ml

Gradient descent is an optimization algorithm used to minimize errors in a model by adjusting its parameters iteratively. It works by moving in the direction of the steepest decrease of the [[loss function]].

## Q&A's

What is [[Batch gradient descent]]?;; computes the gradient of the entire dataset,

What is [[Stochastic Gradient Descent]]?;; updates the model parameters based on the gradient of a single randomly chosen data point. 

What is [[Mini-batch gradient descent]]?;; Is a compromise of [[Batch gradient descent]] and [[Stochastic Gradient Descent]].