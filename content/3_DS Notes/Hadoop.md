
1. **Architecture**:
   - **Open-Source Framework**: Hadoop is an open-source framework for distributed storage and processing of large datasets using clusters of commodity hardware.
   - **Distributed File System**: The Hadoop Distributed File System (HDFS) stores data across multiple machines, providing high throughput access to data.
   - **MapReduce**: Originally designed for [[Batch Processing]] using the MapReduce programming model, though newer frameworks like Apache Spark are often used now.

2. **Data Storage**:
   - **Unstructured, Semi-Structured, and Structured Data**: Hadoop can handle a wide variety of data formats, including unstructured, semi-structured, and structured data.
   - **Scalable Storage**: HDFS can store vast amounts of data by adding more nodes to the cluster.

3. **Management**:
   - **Complex Management**: Requires more administrative effort to manage and maintain the infrastructure, including handling failures, load balancing, and tuning.

4. **Performance**:
   - **[[Batch Processing]]**: Hadoop is optimized for batch processing of large datasets, though it can be less efficient for real-time processing compared to other systems.
   - **Latency**: Higher latency for query processing compared to Snowflake, particularly for complex analytical queries.

5. **Use Cases**:
   - **Big Data Processing**: Ideal for large-scale data processing tasks, including ETL (Extract, Transform, Load), data mining, and large-scale machine learning.
   - **Data Lake**: Commonly used as a data lake to store vast amounts of raw data.