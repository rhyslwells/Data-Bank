## Description 

- split tree level wise


XGBoost may involve parameters like eta and max depth.
## **Advantages**:
  - **Accuracy**: XGM is known for its accuracy and robustness in various machine learning tasks.
  - **Regularization**: Supports different forms of regularization to prevent overfitting.
  - **Flexibility**: Offers a wide range of hyperparameters for fine-tuning models.
- **Relative Use Cases**:
  - Suitable for a wide range of applications, including structured data and tabular datasets.
  - Effective when interpretability of the model is important and extensive hyperparameter tuning is feasible.