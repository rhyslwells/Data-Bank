# Description

- splits the tree leaf wise
- as [[Gradient Descent]] has [[learning rate]]
- dart is the best
- Need to define parameters in a dictionary


[LINK](https://www.youtube.com/watch?v=n_ZMQj09S6w)



 
 LightGBM may involve tuning parameters like learning rate and number of leaves

## **Advantages**:
  - **Speed**: LGBM is renowned for its speed, often outperforming other gradient boosting implementations.
  - **Memory Usage**: It optimizes memory usage, enabling efficient handling of large datasets.
  - **Leaf-Wise Growth**: LGBM grows trees leaf-wise, leading to faster convergence.
  - **Parallel and GPU Learning**: Supports parallel and GPU learning for further speedup.
- **Relative Use Cases**:
  - Ideal for large datasets and applications where speed is crucial.
  - Efficient when dealing with high-dimensional data and categorical features.
